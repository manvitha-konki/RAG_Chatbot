{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMUIqei3T0i3"
      },
      "source": [
        "**LangChain -** provides a modular framework and tools to integrate LLMs with external data sources and software.\n",
        "\n",
        "**LLM -** understand, generate, and process human-like language from vast amounts of text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiMEU6-d2K0T",
        "outputId": "cfab15bd-f303-4b5d-990c-d1ff28a92bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/67.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m920.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.1/788.1 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai langchain-core langchain_community doc2txt pypdf langchain_chroma sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tELqCDEX2ePa",
        "outputId": "a8cd6315-5ee6-4101-f8ab-612c7cdfc622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.1.10)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.3.75)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.7)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.74.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.75->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.34.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.75->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-google-genai langchain chromadb pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CwN31EdbU6eS"
      },
      "outputs": [],
      "source": [
        "import getpass    # The input read defaults to \"Password\"\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H71tDMdaU_sv"
      },
      "source": [
        "Get the API keys of Google and LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yUtK0ia2BaD",
        "outputId": "84304b57-5771-4931-9bf2-76f28d842411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for Google Gemini: ··········\n"
          ]
        }
      ],
      "source": [
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqquusl_2D0P",
        "outputId": "beb16def-7027-4df8-c0ce-5bd238afc46e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for Langchain: ··········\n"
          ]
        }
      ],
      "source": [
        "if not os.environ.get(\"LANGCHAIN_API_KEY\"):\n",
        "  os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter API key for Langchain: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NowWec7z2TKO",
        "outputId": "d2caea8c-bb8d-4478-ee9e-3922830935bb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.3.27'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import langchain\n",
        "langchain.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6sbBijX72Whk"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"     # Logging every step your LangChain app takes\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"BizLens\"     # Logging in Langsmith with this given name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rgCeUI0VLnN"
      },
      "source": [
        "Initialize Gemini (LLM)  with LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cWWQ0e4Z26iZ"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "#  model name for Gemini Pro, which is typically 'gemini-1.0-pro' (slow and used when complex)\n",
        "# 'temperature' -> controls randomness of output. Lower = more focused/deterministic, higher = more creative/random.\n",
        "# 'top_p' -> controls nucleus sampling (how diverse the output is). Lower = safer/less diverse, higher = more diverse.\n",
        "google_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",   # It is Gemini model variant\n",
        "    temperature=0.9,            # It adds creativity/randomness to responses\n",
        "    top_p=0.8                   # Nucleus sampling for probability cutoff\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft_cBMSfciTI",
        "outputId": "1614de9d-a080-465d-e7a8-6f085033833b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Why don't scientists trust atoms? \\n\\nBecause they make up everything!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--5516452c-ba1f-4661-b89f-eac884c41a25-0', usage_metadata={'input_tokens': 4, 'output_tokens': 17, 'total_tokens': 21, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_response = google_llm.invoke(\"Tell me a joke\")\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCF2s2ylZEm7"
      },
      "source": [
        "**Outout Parsers** - responsible for taking the output of a model and transforming it to a more suitable format as normal output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T5SLgGJgqkj"
      },
      "source": [
        "**Different Output Parsers:**\n",
        "\n",
        "- **StrOutputParser:** Returns the model’s output as a plain string.\n",
        "- **JsonOutputParser:** model output is valid JSON and parses it into a Python dict.\n",
        "- **PydanticOutputParser:** Uses a Pydantic model to validate and structure the output.\n",
        "-** CommaSeparatedListOutputParser: **Converts output like \"apple, banana, orange\" into a Python list.\n",
        "-** ListOutputParser**: Parses structured list-style outputs (like bullet points) into a Python list.\n",
        "- **RegexParser**: structured info from the output using a regex pattern.\n",
        "- **OutputFixingParser**: Wraps another parser and auto-corrects invalid outputs\n",
        "- **RetryOutputParser**: Retries parsing if the output doesn’t fit the schema, prompting the LLM again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VqyjLu40cjU7",
        "outputId": "51770fc9-7069-41a1-ff1c-fb9529b833b3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Why don't scientists trust atoms? \\n\\nBecause they make up everything!\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Formating the output from AI response to normal output\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "output_parser.invoke(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpFZtvFnaGeW"
      },
      "source": [
        "Creating a chain of model, output parser, etc to automate multi-step tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eQWW0tRTckvc",
        "outputId": "1ab7557f-2292-46e7-be58-542daffb3862"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Why don't scientists trust atoms? \\n\\nBecause they make up everything!\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a Chain that do all at once rather than doing all in different steps\n",
        "chain = google_llm | output_parser\n",
        "chain.invoke(\"Tell me a Joke\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "zmhyVDMacl_l",
        "outputId": "bdc4a796-b4a7-4153-acb0-f47713a6f9a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Recent news from India is varied and fast-paced.  To give you a useful summary, I need some specifics.  What areas are you interested in?  For example, are you interested in:\\n\\n* **Politics:**  Government decisions, elections, policy changes, etc.?\\n* **Business/Economy:**  Market trends, inflation, new investments, etc.?\\n* **Social Issues:**  Caste-based violence, religious tensions, women's rights, etc.?\\n* **Technology:**  Developments in the Indian tech sector, digital initiatives, etc.?\\n* **International Relations:**  India's relationships with other countries, diplomatic efforts, etc.?\\n* **Sports:**  Cricket, other sporting events, etc.?\\n* **Culture:**  Film releases, festivals, art, etc.?\\n* **Disasters/Accidents:**  Natural disasters, major accidents, etc.?\\n\\n\\nPlease tell me what aspects of Indian news you'd like to know more about, and I'll do my best to provide a concise summary of recent events.\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"Recent news in india\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LAln0hCAECp"
      },
      "source": [
        "### Structured Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyinFFgl-bA7"
      },
      "source": [
        "**Uses of Pydantic:**\n",
        "\n",
        "- **API development:** Validates request/response data in FastAPI and generates automated docs.\n",
        "- **Data processing & ETL:** Cleans and validates data at ingestion to ensure quality.\n",
        "- **Configuration management:** Loads and validates settings from env variables or files.\n",
        "- **Object serialization:** Easily converts models to/from dicts and JSON.\n",
        "- **Data modeling & integrity:** Defines schemas with validation to ensure reliable domain objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WGOIFfSicnEq"
      },
      "outputs": [],
      "source": [
        "# BaseModel - BaseModel provides validation, parsing, serialization, and default/constraint handling for data models.\n",
        "# Field - Used inside BaseModel to give extra information about each field, like:\n",
        "    # Default values\n",
        "    # Metadata (title, description)\n",
        "    # Validation constraints (min length, max value, regex, etc.)\n",
        "\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVFNVP6YcoeM",
        "outputId": "ce64fe79-18b5-46e0-e49b-8b55399b625c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MobileReview(phone_model='Galaxy S21', rating=4.0, pros=['Gorgeous screen', 'Insane camera, especially at night', 'Solid battery life'], cons=['Pricey', 'No charger included', 'New button layout'], summary='Great phone, but a few annoying quirks keep it from being perfect.')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Defined Structure for the model\n",
        "class MobileReview(BaseModel):\n",
        "  phone_model: str = Field(description = \"Name and Model of the phone\")\n",
        "  rating: float = Field(description = \"Rating of the phone\")\n",
        "  pros: List[str] = Field(description = \"List of positive aspects\")\n",
        "  cons: List[str] = Field(description = \"List of negative aspects\")\n",
        "  summary: str = Field(description = \"Brief summary of the review\")\n",
        "\n",
        "review_text = \"\"\"\n",
        "Just got my hands on the new Galaxy S21 and wow, this thing is slick! The screen is gorgeous, colors pop like crazy. Camera's insane too, especially at night - my Insta game's never been\n",
        "stronger. Battery life's solid, lasts me all day no problem.\n",
        "\n",
        "Not gonna lie though, it's pretty pricey. And what's with ditching the charger? C'mon Samsung.\n",
        "Also, still getting used to the new button layout, keep hitting Bixby by mistake.\n",
        "\n",
        "Overall I'd say it's a solid 4 out of 5. Great phone, but a few annoying quirks keep it from being perfect.\n",
        "If you're due for an upgrade, definitely worth checking out!\n",
        "\"\"\"\n",
        "\n",
        "# Output in custum structured then use this with_structured_output method\n",
        "structured_llm = google_llm.with_structured_output(MobileReview)\n",
        "output = structured_llm.invoke(review_text)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7DQALkNcpt1",
        "outputId": "065b6b7d-d73f-4f5a-f5cd-df11dd68b1d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Gorgeous screen', 'Insane camera, especially at night', 'Solid battery life']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.pros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk4931JfcrQW",
        "outputId": "467b7b24-4590-4416-df4a-20bddac456b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv8hDP_mctyD"
      },
      "source": [
        "### Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd4WW8nxcsJb",
        "outputId": "5aebfe6e-5ed3-4273-e4cc-18ca2eabd090"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='tell me a joke about sports', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# defines and structure prompts\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
        "prompt.invoke({\"topic\": \"sports\"})    # Template with value substituted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fmz5WdH_cvYk",
        "outputId": "20d98ec9-a15e-4954-90a5-96f461e8f3c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Why are kids like bubbles?  Because they're fun to watch until they burst!\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = prompt | google_llm | output_parser\n",
        "chain.invoke({\"topic\": \"kids\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0QUeXlnCcwWo",
        "outputId": "489879c5-23e3-45a6-8507-97b611d980cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Why are kids like bubbles?  Because they're a lot of fun until they pop!\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Putting everything together from start\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Defining the prompt\n",
        "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
        "\n",
        "# Initializing the Model(LLM)\n",
        "google_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
        "\n",
        "# Creating output parser\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Compose Chain\n",
        "chain = prompt | google_llm | output_parser\n",
        "\n",
        "# Use Chain\n",
        "result = chain.invoke({\"topic\": \"kids\"})\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfsQJ8Brc1i0"
      },
      "source": [
        "### LLM Messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WEnHo5Rc3Hr"
      },
      "source": [
        "Different type of messages:\n",
        "\n",
        "- AI message -> LLM’s response.\n",
        "- Human message -> user’s input/question.\n",
        "- System message -> system message is a prompt that guides the model's behavior, environment setup / role assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii0RKEmHczAf",
        "outputId": "1fadb6cd-bde0-422a-e065-bd3a64a56515"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Why do programmers prefer dark mode?\\n\\nBecause light attracts bugs!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--001ca7c4-d641-4fab-aba4-45906e29ccd5-0', usage_metadata={'input_tokens': 13, 'output_tokens': 14, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "# Custum message\n",
        "system_message = SystemMessage(content = \"You are a helpful assistant that tells jokes.\")\n",
        "human_message = HumanMessage(content = \"Tell me about programming\")\n",
        "google_llm.invoke([system_message, human_message])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBU5ME5Gc40z",
        "outputId": "30aef973-bd07-48b9-822c-e0b78bb7c419"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant that tells jokes.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about sports', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Putting system and human messages in to a template\n",
        "template = ChatPromptTemplate([\n",
        "    (\"system\", \"You are a helpful assistant that tells jokes.\"),\n",
        "    (\"human\", \"Tell me about {topic}\")\n",
        "])\n",
        "\n",
        "# Setting the prompt in the placeholder value\n",
        "prompt_value = template.invoke({\"topic\": \"sports\"})\n",
        "prompt_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae95zeMTdChq"
      },
      "source": [
        "## RAG - Retrieval Augumented Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "l6Tnp9NWdCtd"
      },
      "outputs": [],
      "source": [
        "# !pip install \"unstructured[excel]\" msoffcrypto-tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WlZSEzP6lUpB"
      },
      "outputs": [],
      "source": [
        "# !pip install docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9Rn-2qU3dD4M"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxlPZDsCtPi9"
      },
      "source": [
        "**Different types of text_splitters:**\n",
        "\n",
        "- **CharacterTextSplitter:**\n",
        "    - Splits by character length (simple cutoff).\n",
        "    - May break sentences unnaturally.\n",
        "- **RecursiveCharacterTextSplitter:**\n",
        "    - Splits hierarchically: tries paragraphs → sentences → words.\n",
        "    - Produces meaningful chunks (preferred in production).\n",
        "- **TokenTextSplitter:**\n",
        "    - Splits based on LLM tokens (not characters).\n",
        "- **NLTKTextSplitter:**\n",
        "    - Splits based on linguistic units (sentences, paragraphs).\n",
        "    - Requires extra dependencies (nltk, spacy).\n",
        "- **MarkdownHeaderTextSplitter:**\n",
        "    - Splits Markdown docs by headers (#, ##, etc.).\n",
        "- **HTMLHeaderTextSplitter:**\n",
        "     - Splits HTML documents by header tags (\\<h1>, \\<h2>, etc.).\n",
        "- **CodeTextSplitter:**\n",
        "     - Splits source code files by functions/classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pjJjQPMMdGKB"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader  # Helps to load documents\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings     # Embeddings to get the relational vector for each token\n",
        "from langchain_core.documents import Document     # Every type is converted to this LLM type doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JQPciPyNaiOw"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# splitting the documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len,\n",
        "    add_start_index = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6eoMpHeSkjRq"
      },
      "outputs": [],
      "source": [
        "docx_loader = Docx2txtLoader(\"/content/GreenGrow Innovations_ Company History.docx\")\n",
        "documents = docx_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaWDosdQFsg5",
        "outputId": "8d33cbf5-0976-4a64-fc8a-b540b2f99b06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/GreenGrow Innovations_ Company History.docx'}, page_content=\"GreenGrow Innovations was founded in 2010 by Sarah Chen and Michael Rodriguez, two agricultural engineers with a passion for sustainable farming. The company started in a small garage in Portland, Oregon, with a simple mission: to make farming more environmentally friendly and efficient.\\n\\n\\n\\nIn its early days, GreenGrow focused on developing smart irrigation systems that could significantly reduce water usage in agriculture. Their first product, the WaterWise Sensor, was launched in 2012 and quickly gained popularity among local farmers. This success allowed the company to expand its research and development efforts.\\n\\n\\n\\nBy 2015, GreenGrow had outgrown its garage origins and moved into a proper office and research facility in the outskirts of Portland. This move coincided with the development of their second major product, the SoilHealth Monitor, which used advanced sensors to analyze soil composition and provide real-time recommendations for optimal crop growth.\\n\\n\\n\\nThe company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\n\\n\\n\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\n\\n\\n\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\")]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNyKVSAhk3Jg",
        "outputId": "fc53c080-d751-4c12-a892-810559ec7288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of splits: 2\n"
          ]
        }
      ],
      "source": [
        "splits = text_splitter.split_documents(documents)\n",
        "print(f\"Number of splits: {len(splits)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yJ2xO2-lgqo",
        "outputId": "738092d3-be8d-4b7c-85f3-0b96434c77aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/GreenGrow Innovations_ Company History.docx', 'start_index': 0}, page_content='GreenGrow Innovations was founded in 2010 by Sarah Chen and Michael Rodriguez, two agricultural engineers with a passion for sustainable farming. The company started in a small garage in Portland, Oregon, with a simple mission: to make farming more environmentally friendly and efficient.\\n\\n\\n\\nIn its early days, GreenGrow focused on developing smart irrigation systems that could significantly reduce water usage in agriculture. Their first product, the WaterWise Sensor, was launched in 2012 and quickly gained popularity among local farmers. This success allowed the company to expand its research and development efforts.\\n\\n\\n\\nBy 2015, GreenGrow had outgrown its garage origins and moved into a proper office and research facility in the outskirts of Portland. This move coincided with the development of their second major product, the SoilHealth Monitor, which used advanced sensors to analyze soil composition and provide real-time recommendations for optimal crop growth.')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKP3BT0OljRP",
        "outputId": "6d57dd47-76ad-4a82-95cd-0db6f79de593"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': '/content/GreenGrow Innovations_ Company History.docx',\n",
              " 'start_index': 0}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "G30g89f3RMkK",
        "outputId": "b23cb6f8-9235-4469-8c98-eb70cef1d7ac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Company: QuantumNext Systems\\n\\nHeadquarters: QuantumNext Systems is headquartered in Bangalore, Karnataka, India. The company, specializing in quantum computing and advanced data processing, is situated in the bustling tech metropolis of Bangalore, often referred to as the \"Silicon Valley of India.\" From this technology capital, QuantumNext Systems is well-positioned to tap into India\\'s rich pool of engineering talent and growing tech ecosystem, enabling it to push the boundaries of computational innovation.'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42al6gN9wSrn"
      },
      "source": [
        "#### Load Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Qlwwl12jl0IF"
      },
      "outputs": [],
      "source": [
        "# Function to load documents from a folder\n",
        "def load_documents(folder_path: str) -> List[Document]:\n",
        "  documents = []\n",
        "  for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    if filename.endswith('.pdf'):\n",
        "      loader = PyPDFLoader(file_path)\n",
        "    elif filename.endswith('docx'):\n",
        "      loader = Docx2txtLoader(file_path)\n",
        "    else:\n",
        "      print(f\"Unsupported file type: {filename}\")\n",
        "      continue\n",
        "    documents.extend(loader.load())\n",
        "  return documents\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len,\n",
        "    add_start_index = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQKF0JUHvsxU",
        "outputId": "71956d19-c0b1-49ee-9d6e-350b843d0b37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsupported file type: .config\n",
            "Unsupported file type: sample_data\n",
            "Loaded 5 documents from the folder.\n",
            "Split the documents into 8 chunks.\n"
          ]
        }
      ],
      "source": [
        "# Load Documents from a folder\n",
        "folder_path = \"/content\"\n",
        "documents = load_documents(folder_path)\n",
        "\n",
        "print(f\"Loaded {len(documents)} documents from the folder.\")\n",
        "splits = text_splitter.split_documents(documents)\n",
        "print(f\"Split the documents into {len(splits)} chunks.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSvzSYaawV0I"
      },
      "source": [
        "#### Get Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDgEiIChwBvh",
        "outputId": "0ecbc15b-1f90-46e8-84a7-c28f8732dab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings shape: 8\n"
          ]
        }
      ],
      "source": [
        "# Embedding documents\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
        "\n",
        "# Get embeddings for multiple documents\n",
        "multi_doc_embeddings = embeddings.embed_documents([split.page_content for split in splits])\n",
        "print(f\"Embeddings shape: {len(multi_doc_embeddings)}\")   # Embeddings for different documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJJE-Pq6wmUA",
        "outputId": "c76cd815-df2e-4c99-b045-6205837ac674"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.020223723724484444,\n",
              " -0.019797246903181076,\n",
              " -0.0380454882979393,\n",
              " -0.04309780150651932,\n",
              " 0.11615443229675293,\n",
              " 0.02160935290157795,\n",
              " 0.015302896499633789,\n",
              " -0.00768645154312253,\n",
              " 0.008013720624148846,\n",
              " 0.048679474741220474,\n",
              " -0.039101000875234604,\n",
              " 0.008384802378714085,\n",
              " -0.035774387419223785,\n",
              " -0.024990728124976158,\n",
              " 0.00047951252781786025,\n",
              " -0.012532973662018776,\n",
              " -0.016729529947042465,\n",
              " 0.007844334468245506,\n",
              " -0.00662657618522644,\n",
              " -0.009797823615372181,\n",
              " 0.03647154942154884,\n",
              " 0.0038728113286197186,\n",
              " 0.013231532648205757,\n",
              " 0.013576321303844452,\n",
              " -0.013882886618375778,\n",
              " -0.051442813128232956,\n",
              " 0.011697376146912575,\n",
              " -0.050200991332530975,\n",
              " -0.02769986167550087,\n",
              " 0.010265843011438847,\n",
              " -0.020384538918733597,\n",
              " 0.011846241541206837,\n",
              " -0.048316486179828644,\n",
              " 0.0250454880297184,\n",
              " -0.01130848377943039,\n",
              " -0.0044659036211669445,\n",
              " -0.03487629070878029,\n",
              " 0.002629740396514535,\n",
              " -0.01181736122816801,\n",
              " 0.01149409357458353,\n",
              " 0.005383891519159079,\n",
              " -0.04249626398086548,\n",
              " -0.0227237306535244,\n",
              " -0.02167748101055622,\n",
              " 0.00416202936321497,\n",
              " -0.02667762152850628,\n",
              " -0.04192737862467766,\n",
              " 0.03249796852469444,\n",
              " 0.036141976714134216,\n",
              " -0.03796713054180145,\n",
              " 0.028893612325191498,\n",
              " -0.015256538987159729,\n",
              " 0.0412178672850132,\n",
              " -0.0011996611719951034,\n",
              " 0.028793208301067352,\n",
              " -0.00894066970795393,\n",
              " 0.012792174704372883,\n",
              " 0.0037571624852716923,\n",
              " 0.005769722163677216,\n",
              " 0.019689183682203293,\n",
              " 0.0035157790407538414,\n",
              " 0.023837435990571976,\n",
              " 0.02419028803706169,\n",
              " 0.026660792529582977,\n",
              " 0.010390587151050568,\n",
              " -0.07025288790464401,\n",
              " -0.03304973617196083,\n",
              " 0.030973438173532486,\n",
              " 0.04832378029823303,\n",
              " -0.006247138604521751,\n",
              " 0.01658697798848152,\n",
              " -0.021976327523589134,\n",
              " 0.06863029301166534,\n",
              " -0.07739772647619247,\n",
              " -0.02480883151292801,\n",
              " -0.14454853534698486,\n",
              " -0.030345501378178596,\n",
              " 0.08482617884874344,\n",
              " 0.04536188766360283,\n",
              " 0.0036438151728361845,\n",
              " -0.012730012647807598,\n",
              " -0.050775665789842606,\n",
              " -0.049264516681432724,\n",
              " -0.025693848729133606,\n",
              " -0.029307693243026733,\n",
              " 0.023138180375099182,\n",
              " -0.015231480821967125,\n",
              " -0.0028771518263965845,\n",
              " -0.0037607126869261265,\n",
              " 0.011023380793631077,\n",
              " -0.00043168404954485595,\n",
              " 0.015806840732693672,\n",
              " 0.009218334220349789,\n",
              " -0.051197994500398636,\n",
              " -0.004746471531689167,\n",
              " 0.07579521089792252,\n",
              " -0.017519576475024223,\n",
              " -0.06422494351863861,\n",
              " 0.04123912751674652,\n",
              " -0.05248606204986572,\n",
              " 0.049901872873306274,\n",
              " 0.00017060223035514355,\n",
              " -0.06112882122397423,\n",
              " 0.010000277310609818,\n",
              " 0.05049297958612442,\n",
              " 0.034305326640605927,\n",
              " -0.007884440943598747,\n",
              " 0.03529506176710129,\n",
              " -0.024345306679606438,\n",
              " 0.02654239349067211,\n",
              " -0.05107278749346733,\n",
              " 0.020406648516654968,\n",
              " 0.002517537446692586,\n",
              " -0.030884794890880585,\n",
              " 0.0772114023566246,\n",
              " -0.026082688942551613,\n",
              " 0.0097381342202425,\n",
              " 0.06610392034053802,\n",
              " 0.03058825433254242,\n",
              " 0.025463150814175606,\n",
              " 0.054433245211839676,\n",
              " 0.00541453342884779,\n",
              " 0.04047129675745964,\n",
              " -0.008691730909049511,\n",
              " -0.013881493359804153,\n",
              " 0.023335451260209084,\n",
              " 0.002007685136049986,\n",
              " 0.054106056690216064,\n",
              " 0.017444757744669914,\n",
              " -0.03653835132718086,\n",
              " -0.018215050920844078,\n",
              " -0.03050933964550495,\n",
              " -0.03458334133028984,\n",
              " -0.003012958914041519,\n",
              " 0.053931523114442825,\n",
              " 0.08869359642267227,\n",
              " 0.04575594514608383,\n",
              " -0.046477120369672775,\n",
              " 0.02902047149837017,\n",
              " 0.017504211515188217,\n",
              " -0.03319608420133591,\n",
              " 0.025386430323123932,\n",
              " -0.007183220703154802,\n",
              " 0.02423311211168766,\n",
              " 0.00610466580837965,\n",
              " 0.06491000205278397,\n",
              " -0.045465774834156036,\n",
              " 0.048940934240818024,\n",
              " 0.05331533029675484,\n",
              " -0.04972624033689499,\n",
              " -0.04299725219607353,\n",
              " 0.0005213856929913163,\n",
              " -0.012738468125462532,\n",
              " 0.018092315644025803,\n",
              " 0.022091591730713844,\n",
              " 0.004583750385791063,\n",
              " -0.011321852914988995,\n",
              " 0.01873868517577648,\n",
              " -0.020362548530101776,\n",
              " -0.027451209723949432,\n",
              " 0.010120999999344349,\n",
              " -0.01806117594242096,\n",
              " 0.06809284538030624,\n",
              " 0.06196840479969978,\n",
              " -0.04471415653824806,\n",
              " -0.04692726954817772,\n",
              " -0.0021195753943175077,\n",
              " -0.006112746428698301,\n",
              " -0.021659232676029205,\n",
              " 0.044134799391031265,\n",
              " -0.013404526747763157,\n",
              " 0.05610872432589531,\n",
              " -0.024041492491960526,\n",
              " -0.027853304520249367,\n",
              " -0.004559507127851248,\n",
              " -0.07003381848335266,\n",
              " -0.0019438030431047082,\n",
              " -0.005635542795062065,\n",
              " -0.014487791806459427,\n",
              " 0.007349435240030289,\n",
              " -0.007580201141536236,\n",
              " -0.028070997446775436,\n",
              " 0.004989739507436752,\n",
              " 0.03758389502763748,\n",
              " -0.013744618743658066,\n",
              " -0.027217064052820206,\n",
              " 0.0458226315677166,\n",
              " 0.005758835468441248,\n",
              " -0.04725813865661621,\n",
              " 0.06726773828268051,\n",
              " -0.002910410286858678,\n",
              " -0.01014928612858057,\n",
              " -0.07507394254207611,\n",
              " -0.054048389196395874,\n",
              " -0.0019047147361561656,\n",
              " 0.0013505083043128252,\n",
              " 0.07127850502729416,\n",
              " 0.010975026525557041,\n",
              " 0.025085626170039177,\n",
              " -0.004298495128750801,\n",
              " 0.011423265561461449,\n",
              " 0.06420663744211197,\n",
              " -0.01398350391536951,\n",
              " 0.024944989010691643,\n",
              " -0.0005827312124893069,\n",
              " -0.015411661006510258,\n",
              " 0.02231609635055065,\n",
              " -0.0071905083023011684,\n",
              " -0.04808463156223297,\n",
              " 0.05674111470580101,\n",
              " -0.03235514089465141,\n",
              " 0.0684598758816719,\n",
              " -0.036908846348524094,\n",
              " 0.007084246724843979,\n",
              " 0.03887369856238365,\n",
              " -0.04549752548336983,\n",
              " 0.02534889429807663,\n",
              " 0.027752192690968513,\n",
              " -0.007056348025798798,\n",
              " -0.01241759117692709,\n",
              " 0.008063835091888905,\n",
              " 0.05783491209149361,\n",
              " -0.04613439738750458,\n",
              " 0.016700226813554764,\n",
              " -0.006596306338906288,\n",
              " 0.03885197639465332,\n",
              " 0.004732801578938961,\n",
              " -0.006488468963652849,\n",
              " 0.047530289739370346,\n",
              " -0.02108818292617798,\n",
              " -0.033520426601171494,\n",
              " 0.045560725033283234,\n",
              " 0.006746293511241674,\n",
              " -0.01898270845413208,\n",
              " 0.06983450055122375,\n",
              " -0.013467901386320591,\n",
              " 0.03718980774283409,\n",
              " 0.03359853848814964,\n",
              " 0.05798417329788208,\n",
              " 0.01204055268317461,\n",
              " 0.007632359862327576,\n",
              " 0.026748312637209892,\n",
              " 0.04291040450334549,\n",
              " 0.040065947920084,\n",
              " -0.08568067103624344,\n",
              " -0.011053591966629028,\n",
              " -0.0845303162932396,\n",
              " 0.0421338751912117,\n",
              " 0.025631939992308617,\n",
              " 0.045087359845638275,\n",
              " 0.011612295173108578,\n",
              " -0.023427007719874382,\n",
              " -0.00982750952243805,\n",
              " -0.008267239667475224,\n",
              " -0.06788483262062073,\n",
              " 0.051926638931035995,\n",
              " -0.062111515551805496,\n",
              " -0.005172376986593008,\n",
              " -0.03152460232377052,\n",
              " -0.027260184288024902,\n",
              " 0.05241767317056656,\n",
              " -0.03938191756606102,\n",
              " 0.04622486233711243,\n",
              " -0.00919522624462843,\n",
              " 0.017954522743821144,\n",
              " -0.008518539369106293,\n",
              " 0.004589893855154514,\n",
              " -0.06284379959106445,\n",
              " -0.010268019512295723,\n",
              " 0.030700918287038803,\n",
              " 0.003179345279932022,\n",
              " -0.062301065772771835,\n",
              " 0.025462845340371132,\n",
              " -0.024160485714673996,\n",
              " -0.008191775530576706,\n",
              " -0.030172089114785194,\n",
              " -0.005868404172360897,\n",
              " 0.06115205958485603,\n",
              " 0.045423153787851334,\n",
              " -0.04181881994009018,\n",
              " 0.006362275220453739,\n",
              " 0.01839904673397541,\n",
              " 0.0035529141314327717,\n",
              " -0.06467333436012268,\n",
              " -0.024187598377466202,\n",
              " -0.000559054606128484,\n",
              " -0.036902040243148804,\n",
              " -0.04270990565419197,\n",
              " 0.004598961211740971,\n",
              " -0.06799287348985672,\n",
              " -0.04803766682744026,\n",
              " -0.00963084027171135,\n",
              " 0.028374459594488144,\n",
              " -0.008894736878573895,\n",
              " -0.04348679631948471,\n",
              " 0.00534941116347909,\n",
              " -0.04274720698595047,\n",
              " 0.01675986684858799,\n",
              " -0.010296114720404148,\n",
              " -0.038557425141334534,\n",
              " -0.0012810032349079847,\n",
              " -0.049629952758550644,\n",
              " -0.03462165221571922,\n",
              " -0.05420394986867905,\n",
              " 0.02018185332417488,\n",
              " -0.00035930328886024654,\n",
              " 0.012536263093352318,\n",
              " -0.06221567094326019,\n",
              " 0.0204454492777586,\n",
              " 0.027946094051003456,\n",
              " 0.012238013558089733,\n",
              " -0.029404310509562492,\n",
              " -0.00836651399731636,\n",
              " -0.026958631351590157,\n",
              " 0.012060415931046009,\n",
              " 0.07808119058609009,\n",
              " -0.0013208913151174784,\n",
              " -0.00815445277839899,\n",
              " 0.027314255014061928,\n",
              " 0.01810484379529953,\n",
              " -0.020331325009465218,\n",
              " 0.10053019225597382,\n",
              " 0.03077518567442894,\n",
              " -0.005087926052510738,\n",
              " -0.015561375766992569,\n",
              " 0.07286563515663147,\n",
              " -0.011120113544166088,\n",
              " -0.011811453849077225,\n",
              " -0.02267616055905819,\n",
              " 0.02218971587717533,\n",
              " -0.05981837213039398,\n",
              " 0.02878839150071144,\n",
              " 0.0075256722047924995,\n",
              " 0.02984813041985035,\n",
              " -0.02971082180738449,\n",
              " 0.02724580466747284,\n",
              " -0.055845800787210464,\n",
              " 0.004372771829366684,\n",
              " -0.014669843949377537,\n",
              " -0.022368473932147026,\n",
              " -0.014739220961928368,\n",
              " 0.02821878343820572,\n",
              " -0.03728162869811058,\n",
              " -0.032269202172756195,\n",
              " -0.0010812078835442662,\n",
              " -0.04175901785492897,\n",
              " -0.05156732350587845,\n",
              " 0.07103150337934494,\n",
              " 0.06427277624607086,\n",
              " 0.016638435423374176,\n",
              " 0.03772474825382233,\n",
              " 0.0947103276848793,\n",
              " -0.03128967806696892,\n",
              " -0.02516339160501957,\n",
              " -0.03361843153834343,\n",
              " -0.06705091893672943,\n",
              " 0.05612527206540108,\n",
              " -0.017376314848661423,\n",
              " 0.029504764825105667,\n",
              " -0.020945943892002106,\n",
              " -0.003281384939327836,\n",
              " 0.0489780567586422,\n",
              " 0.0027271078433841467,\n",
              " -0.019175540655851364,\n",
              " 0.005460058804601431,\n",
              " -0.001611283514648676,\n",
              " -0.028728419914841652,\n",
              " 0.02253830060362816,\n",
              " -0.007121345493942499,\n",
              " 0.04405377060174942,\n",
              " 0.005781079176813364,\n",
              " 0.006546504329890013,\n",
              " 0.004702405072748661,\n",
              " -0.01700832135975361,\n",
              " 0.029590517282485962,\n",
              " -0.0162308719009161,\n",
              " -0.05248986929655075,\n",
              " -0.064469113945961,\n",
              " 0.01742878556251526,\n",
              " -0.006272851023823023,\n",
              " 0.027368003502488136,\n",
              " 0.019437119364738464,\n",
              " 0.04052349179983139,\n",
              " 0.03278415650129318,\n",
              " -0.02140967734158039,\n",
              " -0.048224613070487976,\n",
              " 0.025409918278455734,\n",
              " 0.056801099330186844,\n",
              " -0.040562860667705536,\n",
              " -0.0016276559326797724,\n",
              " -0.012395782396197319,\n",
              " 0.042487312108278275,\n",
              " 0.08136255294084549,\n",
              " -0.006636768579483032,\n",
              " 0.008128735236823559,\n",
              " -0.023981843143701553,\n",
              " -0.00620261812582612,\n",
              " -0.043596409261226654,\n",
              " 0.006691264919936657,\n",
              " -0.0039907111786305904,\n",
              " -0.0014539806870743632,\n",
              " -0.055513378232717514,\n",
              " -0.024673545733094215,\n",
              " -0.0057127042673528194,\n",
              " -0.03873177990317345,\n",
              " 0.01792006939649582,\n",
              " 0.030048023909330368,\n",
              " -0.046127982437610626,\n",
              " -0.027310214936733246,\n",
              " -0.0395272821187973,\n",
              " 0.009241985157132149,\n",
              " -0.0019235347863286734,\n",
              " 0.06749798357486725,\n",
              " -0.055503759533166885,\n",
              " -0.040460892021656036,\n",
              " -0.01875188946723938,\n",
              " 0.00426055071875453,\n",
              " 0.01198052242398262,\n",
              " 0.017909135669469833,\n",
              " -0.0036723921075463295,\n",
              " 0.013897504657506943,\n",
              " 0.021215667948126793,\n",
              " 0.0021036318503320217,\n",
              " 0.0312630869448185,\n",
              " -0.12243084609508514,\n",
              " 0.009482304565608501,\n",
              " 0.03168785572052002,\n",
              " 0.012163033708930016,\n",
              " 0.034024108201265335,\n",
              " 0.049600452184677124,\n",
              " 0.04969772323966026,\n",
              " -0.02035638689994812,\n",
              " 0.004942018538713455,\n",
              " -0.013254435732960701,\n",
              " -0.040582939982414246,\n",
              " -0.01760542206466198,\n",
              " -0.009450552985072136,\n",
              " 0.04389485344290733,\n",
              " -0.07740731537342072,\n",
              " -0.03020191565155983,\n",
              " 0.06318535655736923,\n",
              " -0.022354625165462494,\n",
              " 0.022923029959201813,\n",
              " -0.061546675860881805,\n",
              " -0.014010446146130562,\n",
              " -0.02543325535953045,\n",
              " 0.022481948137283325,\n",
              " -0.01584853045642376,\n",
              " -0.00615172041580081,\n",
              " -0.06270386278629303,\n",
              " 0.05384046956896782,\n",
              " -0.018760692328214645,\n",
              " -0.02768772281706333,\n",
              " -0.04194452613592148,\n",
              " -0.062232308089733124,\n",
              " -0.04584105312824249,\n",
              " 0.028276415541768074,\n",
              " 0.04952394589781761,\n",
              " -0.030958782881498337,\n",
              " 0.03518529608845711,\n",
              " 0.06395652890205383,\n",
              " -0.0053092315793037415,\n",
              " -0.014709263108670712,\n",
              " -0.09095772355794907,\n",
              " 0.025939464569091797,\n",
              " -0.02906837686896324,\n",
              " -0.024755345657467842,\n",
              " -0.033744700253009796,\n",
              " 0.04005855694413185,\n",
              " 0.0382789745926857,\n",
              " -0.00753712048754096,\n",
              " -0.019719980657100677,\n",
              " -0.003603601362556219,\n",
              " -0.008000628091394901,\n",
              " -0.022778788581490517,\n",
              " -0.006585804745554924,\n",
              " -0.05326519533991814,\n",
              " 0.06542444974184036,\n",
              " -0.052059587091207504,\n",
              " 0.013995908200740814,\n",
              " 0.01572999730706215,\n",
              " -0.0031075298320502043,\n",
              " -0.006199579685926437,\n",
              " 0.01799192652106285,\n",
              " -0.03662944212555885,\n",
              " 0.0026412829756736755,\n",
              " -0.004267243202775717,\n",
              " 0.01581992581486702,\n",
              " -0.04145936667919159,\n",
              " 0.05536401644349098,\n",
              " 0.010229879058897495,\n",
              " 0.0061441389843821526,\n",
              " -0.01858586259186268,\n",
              " -0.04299365356564522,\n",
              " -0.031099364161491394,\n",
              " 0.018533943220973015,\n",
              " -0.012358047068119049,\n",
              " 0.07980211079120636,\n",
              " 0.06213148683309555,\n",
              " -0.011803394183516502,\n",
              " -0.042144130915403366,\n",
              " -0.013024709187448025,\n",
              " 0.015599861741065979,\n",
              " -0.016731208190321922,\n",
              " 0.04023245349526405,\n",
              " -0.02773197926580906,\n",
              " 0.009438220411539078,\n",
              " 0.0037911483086645603,\n",
              " -0.009197725914418697,\n",
              " 0.027157200500369072,\n",
              " 0.05717403441667557,\n",
              " 0.014134222641587257,\n",
              " -0.006929788272827864,\n",
              " -0.007215635851025581,\n",
              " 0.02653498575091362,\n",
              " -0.026572007685899734,\n",
              " 0.004954457748681307,\n",
              " -0.021206950768828392,\n",
              " 0.026331286877393723,\n",
              " -0.0072822002694010735,\n",
              " 0.01579328253865242,\n",
              " 0.02561444602906704,\n",
              " -0.1092759296298027,\n",
              " -0.047661829739809036,\n",
              " 0.009966939687728882,\n",
              " -0.03438975289463997,\n",
              " -0.008370142430067062,\n",
              " 0.01810804009437561,\n",
              " -0.04163721948862076,\n",
              " -0.006785024888813496,\n",
              " -0.028530888259410858,\n",
              " 0.07111527770757675,\n",
              " -0.03478781878948212,\n",
              " -0.0001802287733880803,\n",
              " 0.019970275461673737,\n",
              " -0.019339287653565407,\n",
              " 0.036643993109464645,\n",
              " 0.005002516321837902,\n",
              " -0.008558270521461964,\n",
              " -0.004790329374372959,\n",
              " 0.03688259422779083,\n",
              " -0.026172641664743423,\n",
              " -0.016990140080451965,\n",
              " -0.009711187332868576,\n",
              " -0.0008617601124569774,\n",
              " 0.0022893636487424374,\n",
              " -0.01784241385757923,\n",
              " -0.07853136956691742,\n",
              " -0.01277710497379303,\n",
              " -0.017682021483778954,\n",
              " 0.009951134212315083,\n",
              " 0.029801923781633377,\n",
              " 0.002059870632365346,\n",
              " -0.029945693910121918,\n",
              " -0.017173834145069122,\n",
              " -0.025462426245212555,\n",
              " -0.011403688229620457,\n",
              " -0.017468499019742012,\n",
              " -0.004629631992429495,\n",
              " -0.0075051807798445225,\n",
              " -0.02147112600505352,\n",
              " -0.0019790739752352238,\n",
              " 0.0003309854364488274,\n",
              " 0.04344899579882622,\n",
              " 0.06304314732551575,\n",
              " -0.0029733898118138313,\n",
              " -0.06320022791624069,\n",
              " -0.012315448373556137,\n",
              " 0.018261469900608063,\n",
              " -0.06784703582525253,\n",
              " 0.013653669506311417,\n",
              " -0.05053459480404854,\n",
              " 0.07853297144174576,\n",
              " -0.013441844843327999,\n",
              " 0.08666109293699265,\n",
              " -0.017685439437627792,\n",
              " -0.047105856239795685,\n",
              " -0.0012517357245087624,\n",
              " -0.042492423206567764,\n",
              " 0.038947880268096924,\n",
              " 0.03497319296002388,\n",
              " -0.0004273904487490654,\n",
              " -0.0072815557941794395,\n",
              " 0.014450004324316978,\n",
              " 0.025980867445468903,\n",
              " -0.032043036073446274,\n",
              " 0.10210277885198593,\n",
              " 0.037913206964731216,\n",
              " 0.047409169375896454,\n",
              " -0.010524975135922432,\n",
              " -0.035432569682598114,\n",
              " 0.017276499420404434,\n",
              " 0.016563741490244865,\n",
              " 0.0397673137485981,\n",
              " 0.007083199918270111,\n",
              " -0.01559027936309576,\n",
              " 0.030676400288939476,\n",
              " -0.039075691252946854,\n",
              " -0.013891370967030525,\n",
              " 0.04074252024292946,\n",
              " -0.0005098143010400236,\n",
              " 0.0023514479398727417,\n",
              " 0.04887733981013298,\n",
              " -0.039424628019332886,\n",
              " 0.059563104063272476,\n",
              " 0.032435908913612366,\n",
              " 0.025049453601241112,\n",
              " 0.005473264958709478,\n",
              " 0.05342375487089157,\n",
              " 0.07789768278598785,\n",
              " 0.012398980557918549,\n",
              " -0.03353726863861084,\n",
              " -0.01477918028831482,\n",
              " -0.004197458736598492,\n",
              " -0.035322096198797226,\n",
              " -0.03804229944944382,\n",
              " 0.06800741702318192,\n",
              " 0.005905936937779188,\n",
              " 0.013551989570260048,\n",
              " -0.06157425418496132,\n",
              " -0.011838806793093681,\n",
              " 0.01176636852324009,\n",
              " 0.02992803417146206,\n",
              " 0.0016255478840321302,\n",
              " -0.012517406605184078,\n",
              " -0.008266469463706017,\n",
              " -0.0036063676234334707,\n",
              " -0.012735279276967049,\n",
              " 0.08747345954179764,\n",
              " 0.03123861365020275,\n",
              " 0.04835965856909752,\n",
              " 0.06642266362905502,\n",
              " -0.018171953037381172,\n",
              " 0.02797853574156761,\n",
              " -0.048525191843509674,\n",
              " -0.01908196695148945,\n",
              " 0.008357206359505653,\n",
              " -0.02285832166671753,\n",
              " -0.02235504239797592,\n",
              " 0.010826826095581055,\n",
              " -0.0813869908452034,\n",
              " -0.018127629533410072,\n",
              " 0.00596903869882226,\n",
              " 0.00877685658633709,\n",
              " -0.0058802333660423756,\n",
              " 0.03834719955921173,\n",
              " 0.058936212211847305,\n",
              " -0.08389700949192047,\n",
              " -0.04717569798231125,\n",
              " -0.023800548166036606,\n",
              " -0.037265609949827194,\n",
              " 0.02071768045425415,\n",
              " 0.009490838274359703,\n",
              " -0.03094891831278801,\n",
              " 0.01514756865799427,\n",
              " 0.008568311110138893,\n",
              " -0.010288108140230179,\n",
              " -0.03227894380688667,\n",
              " 0.06396748125553131,\n",
              " -0.007819764316082,\n",
              " -0.018783682957291603,\n",
              " 0.00940373633056879,\n",
              " -0.015093325637280941,\n",
              " 0.017479602247476578,\n",
              " 0.01176892314106226,\n",
              " -0.004093586001545191,\n",
              " -0.03505559638142586,\n",
              " -0.05396929383277893,\n",
              " -0.01844530552625656,\n",
              " 0.04663676396012306,\n",
              " -0.06659577786922455,\n",
              " 0.028379470109939575,\n",
              " 0.06383038312196732,\n",
              " 0.024837825447320938,\n",
              " 0.034359097480773926,\n",
              " 0.09732679277658463,\n",
              " -0.008075790479779243,\n",
              " 0.01072793360799551,\n",
              " 0.016460375860333443,\n",
              " 0.02145134098827839,\n",
              " 0.04718268662691116,\n",
              " 0.04702676832675934,\n",
              " -0.044760510325431824,\n",
              " 0.036736201494932175,\n",
              " 0.0145635437220335,\n",
              " 0.009886564686894417,\n",
              " 0.033003006130456924,\n",
              " -0.04775119945406914,\n",
              " -0.06543923169374466,\n",
              " -0.04078823700547218,\n",
              " 0.038723982870578766,\n",
              " -0.037422552704811096,\n",
              " 0.006491231266409159,\n",
              " 0.044045571237802505,\n",
              " 0.08270101249217987,\n",
              " -0.027699533849954605,\n",
              " -0.014105910435318947,\n",
              " 0.009377418085932732,\n",
              " -0.01638202928006649,\n",
              " 0.026891950517892838,\n",
              " -0.026138700544834137,\n",
              " -0.024678464978933334,\n",
              " -0.023879995569586754,\n",
              " 0.050551995635032654,\n",
              " 0.01815512590110302,\n",
              " 0.011985001154243946,\n",
              " -0.02095205895602703,\n",
              " 0.049060676246881485,\n",
              " 0.024321965873241425,\n",
              " 0.06608933955430984,\n",
              " 0.041913826018571854,\n",
              " -0.0809861347079277,\n",
              " -0.0056123752146959305,\n",
              " 0.022024309262633324,\n",
              " 0.05855550244450569,\n",
              " -0.015038779936730862,\n",
              " 0.008908907882869244,\n",
              " 0.018319452181458473,\n",
              " -0.03592519089579582,\n",
              " 0.049317676573991776,\n",
              " 0.061045076698064804,\n",
              " 0.006131726782768965,\n",
              " 0.0009561324841342866,\n",
              " -0.00102432316634804,\n",
              " -0.05087905377149582,\n",
              " 0.020143045112490654,\n",
              " 0.007567557971924543,\n",
              " -0.011758243665099144,\n",
              " -0.0031889888923615217,\n",
              " 0.0003168633265886456,\n",
              " 0.07387436181306839,\n",
              " -0.02595738135278225,\n",
              " -0.03397010639309883,\n",
              " 0.007414113264530897,\n",
              " -0.028704073280096054,\n",
              " 0.04831375926733017,\n",
              " -0.0010955859906971455,\n",
              " 0.029776567593216896,\n",
              " -0.02726244367659092,\n",
              " -0.04168955609202385,\n",
              " -0.0398406945168972,\n",
              " -0.01137295551598072,\n",
              " 0.010560950264334679,\n",
              " 0.028152041137218475,\n",
              " 0.049654923379421234,\n",
              " -0.04409640654921532,\n",
              " 0.008865882642567158,\n",
              " -0.005799141246825457,\n",
              " 0.05461173504590988,\n",
              " -0.044195786118507385,\n",
              " -0.041259828954935074,\n",
              " -0.044282715767621994,\n",
              " -0.062188055366277695,\n",
              " -0.023688703775405884,\n",
              " 0.045791056007146835,\n",
              " 0.008930395357310772,\n",
              " -0.0024228431284427643,\n",
              " -0.006887875031679869,\n",
              " 0.030707810074090958,\n",
              " 0.0077078677713871,\n",
              " -0.02454224042594433,\n",
              " -0.007465589791536331,\n",
              " 0.022921964526176453,\n",
              " 0.0003966812801081687,\n",
              " 0.0004660813428927213,\n",
              " 0.004375471733510494,\n",
              " -0.04584084451198578,\n",
              " -0.00828856136649847]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_doc_embeddings[0]   # vector representation of one of the document after split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_rdFL0C8xUtc"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain_chroma -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCzwHO6_yel0"
      },
      "source": [
        "#### Create and Persist chroma vector store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt-TAOkWzg8P"
      },
      "source": [
        "- **Creating =** like filling a database table in memory with embeddings.\n",
        "- **Persisting =** like hitting “Save to disk” so you don’t lose your work after closing Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueThh2YkyQ6R",
        "outputId": "aa8b7201-0d5d-4e15-8c19-a1ca77de0664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store created and persisted to ./chroma_db\n"
          ]
        }
      ],
      "source": [
        "# To store all these embeddings we use chromaDB\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Initialize Gemini embedding model\n",
        "embedding_function = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "collection_name = \"my_chatbot_collection\"\n",
        "\n",
        "# Create Chroma vector store with Gemini embeddings\n",
        "vectorstore = Chroma.from_documents(\n",
        "    collection_name=collection_name,\n",
        "    documents=splits,\n",
        "    embedding=embedding_function,\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")\n",
        "\n",
        "vectorstore.persist()\n",
        "print(\"Vector store created and persisted to ./chroma_db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2yWgx-y0OyP"
      },
      "source": [
        "#### Perform Similarity Search - Retrieval and Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YftvW8cT1TeM"
      },
      "source": [
        "Using this similarity search, we get most relevant document. That document and Query are sent together to LLM to get the answer perfectly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kUZtRK-yeDH",
        "outputId": "7c3a005a-db2d-44ac-dce6-ea6b558e191f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "Top 2 most relevant chunks for the query: When was GreenGrow Innovations founded?\n",
            "\n",
            "Result 1:\n",
            "Source: /content/GreenGrow Innovations_ Company History.docx\n",
            "Content: The company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\n",
            "\n",
            "\n",
            "\n",
            "Today, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\n",
            "\n",
            "\n",
            "\n",
            "Despite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\n",
            "\n",
            "Result 2:\n",
            "Source: /content/GreenGrow Innovations_ Company History.docx\n",
            "Content: The company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\n",
            "\n",
            "\n",
            "\n",
            "Today, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\n",
            "\n",
            "\n",
            "\n",
            "Despite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\n",
            "\n",
            "Result 3:\n",
            "Source: /content/Company_ GreenFields BioTech.docx\n",
            "Content: Company: GreenFields BioTech\n",
            "\n",
            "Headquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.\n",
            "\n",
            "Result 4:\n",
            "Source: /content/Company_ GreenFields BioTech.docx\n",
            "Content: Company: GreenFields BioTech\n",
            "\n",
            "Headquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"When was GreenGrow Innovations founded?\"\n",
        "search_results = vectorstore.similarity_search(query)\n",
        "print(len(search_results))\n",
        "\n",
        "print(f\"Top 2 most relevant chunks for the query: {query}\\n\")\n",
        "for i, result in enumerate(search_results, 1):\n",
        "  print(f\"Result {i}:\")\n",
        "  print(f\"Source: {result.metadata.get('source', 'Unknown')}\")\n",
        "  print(f\"Content: {result.page_content}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k270OTWW2eFc"
      },
      "source": [
        "As we cant invoke directly the vectorstore object to llm, so we convert it into retriever object and invoke llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WE-qBmV0ax3",
        "outputId": "c4c5d348-b8d6-497f-c6bd-47d2d3fd027c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'start_index': 979, 'source': '/content/GreenGrow Innovations_ Company History.docx'}, page_content=\"The company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\n\\n\\n\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\n\\n\\n\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\"),\n",
              " Document(metadata={'start_index': 979, 'source': '/content/GreenGrow Innovations_ Company History.docx'}, page_content=\"The company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\n\\n\\n\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\n\\n\\n\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\"),\n",
              " Document(metadata={'source': '/content/Company_ GreenFields BioTech.docx', 'start_index': 0}, page_content='Company: GreenFields BioTech\\n\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.'),\n",
              " Document(metadata={'source': '/content/Company_ GreenFields BioTech.docx', 'start_index': 0}, page_content='Company: GreenFields BioTech\\n\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.')]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retriever object to get all the relevant docs from vector database\n",
        "retriever = vectorstore.as_retriever()\n",
        "retriever.invoke(\"When was GreenGrow Innovations founded?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "4KZgmq9f2R2S"
      },
      "outputs": [],
      "source": [
        "# Creating a template with proper prompts\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\" Answer the question based only on the following context:\n",
        "{context}\n",
        "Question: {question}\n",
        "\n",
        "Answer = \"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMZWDhaK6L3Q",
        "outputId": "fb859e3e-33e2-435d-bba0-445912e5075b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content=' Answer the question based only on the following context:\\n[Document(metadata={\\'source\\': \\'/content/GreenGrow Innovations_ Company History.docx\\', \\'start_index\\': 979}, page_content=\"The company\\'s breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\\\n\\\\n\\\\n\\\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\\\n\\\\n\\\\n\\\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\"), Document(metadata={\\'start_index\\': 979, \\'source\\': \\'/content/GreenGrow Innovations_ Company History.docx\\'}, page_content=\"The company\\'s breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\\\n\\\\n\\\\n\\\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\\\n\\\\n\\\\n\\\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\"), Document(metadata={\\'start_index\\': 0, \\'source\\': \\'/content/Company_ GreenFields BioTech.docx\\'}, page_content=\\'Company: GreenFields BioTech\\\\n\\\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.\\'), Document(metadata={\\'start_index\\': 0, \\'source\\': \\'/content/Company_ GreenFields BioTech.docx\\'}, page_content=\\'Company: GreenFields BioTech\\\\n\\\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.\\')]\\nQuestion: When was GreenGrow innovations founded?\\n\\nAnswer = ', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RunnablePassthrough forwards the input unchanged in pipelines that require no preprocessing.\n",
        "from langchain_core.runnables import RunnablePassthrough   # It is the query that we invoke\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever,\n",
        "        \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        ")\n",
        "rag_chain.invoke(\"When was GreenGrow innovations founded?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Zkzf4rGm_EKg"
      },
      "outputs": [],
      "source": [
        "# Joining all content of all documents into one\n",
        "\n",
        "def doc2str(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9k71PG_AFAH",
        "outputId": "ad58a0a0-e331-45f0-dfb4-ecc7e2a7459c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content=\" Answer the question based only on the following context:\\nThe company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\n\\n\\n\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\n\\n\\n\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\\n\\nThe company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\n\\n\\n\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\n\\n\\n\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\\n\\nCompany: GreenFields BioTech\\n\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.\\n\\nCompany: GreenFields BioTech\\n\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.\\nQuestion: When was GreenGrow innovations founded?\\n\\nAnswer = \", additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RAG Chain with proper formatted docs being put into the prompt.\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | doc2str, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        ")\n",
        "rag_chain.invoke(\"When was GreenGrow innovations founded?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "_pzd7KGpUrGm"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNU9ODLtANvG",
        "outputId": "068ad588-8dd6-4456-b162-af84dd96ed15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('The provided text does not state when GreenGrow Innovations was founded.  It '\n",
            " 'only mentions that their breakthrough was in 2018.')\n"
          ]
        }
      ],
      "source": [
        "# This rag chain invokes the llm and parses output and displays only the page_content from the json returned\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | doc2str, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | google_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "question = \"When was GreenGrow innovations founded?\"\n",
        "response = rag_chain.invoke(question)\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwg7dYmGbuPs"
      },
      "source": [
        "### Conversational RAG - Handling follow up questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "6OfqPmT4AsWx"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "chat_history = []\n",
        "chat_history.extend([\n",
        "    HumanMessage(content = question),\n",
        "    AIMessage(content = response)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmBeqf8GcOiq",
        "outputId": "30b2b6c6-b49c-4360-d77f-086b3fdcc63b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='When was GreenGrow innovations founded?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='The provided text does not state when GreenGrow Innovations was founded.  It only mentions that their breakthrough was in 2018.', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K3TgIMJncPbw",
        "outputId": "a4a8c01d-7807-4d1e-b03b-6bd1eebb67fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Where is GreenGrow Innovations headquartered?'"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This prompt helps in converting the follow-up question into complete question\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder   # Take list of messages dynamically\n",
        ")\n",
        "\n",
        "# Prompt to give answers based on the context and chat history given\n",
        "contextualize_q_system_prompt = (\n",
        "    \"Given a chat history and the latest user question\"\n",
        "    \"Which might reference contexxt in the chat history\"\n",
        "    \"formulate a standalone question which can be understood\"\n",
        "    \"without the chat history, Do not answer the Question,\"\n",
        "    \"Just reformulate it if needed and otherwise return it as is\"\n",
        ")\n",
        "\n",
        "# Creating a template to insert into the retrieval chain.\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),       # List of messages\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Chain built on the contextualised prompt given and used in this chain\n",
        "contextualize_chain = contextualize_q_prompt | google_llm | StrOutputParser()\n",
        "contextualize_chain.invoke({\"input\": \"Where it is headquarted?\", \"chat_history\": chat_history})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwtMF5e4jcS5",
        "outputId": "11fbe450-8521-4e66-feaa-91487e2e1e72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='When was GreenGrow innovations founded?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='The provided text does not state when GreenGrow Innovations was founded.  It only mentions that their breakthrough was in 2018.', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN7G-Qk3fSJ6",
        "outputId": "194e0bca-d867-4835-9f9a-21f9daed9d43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/GreenGrow Innovations_ Company History.docx', 'start_index': 979}, page_content=\"The company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\n\\n\\n\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\n\\n\\n\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\"),\n",
              " Document(metadata={'start_index': 979, 'source': '/content/GreenGrow Innovations_ Company History.docx'}, page_content=\"The company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\n\\n\\n\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\n\\n\\n\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\"),\n",
              " Document(metadata={'source': '/content/Company_ GreenFields BioTech.docx', 'start_index': 0}, page_content='Company: GreenFields BioTech\\n\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.'),\n",
              " Document(metadata={'start_index': 0, 'source': '/content/Company_ GreenFields BioTech.docx'}, page_content='Company: GreenFields BioTech\\n\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.')]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    google_llm, retriever, contextualize_q_prompt\n",
        ")\n",
        "\n",
        "history_aware_retriever.invoke({\"input\": \"Where it is headquarted?\", \"chat_history\": chat_history})\n",
        "# history_aware_retriever.invoke({\"input\": \"Where it is headqueartered?\", \"chat_history\": chatHistory})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "jnGCoQb9hQQp",
        "outputId": "d16846a0-434c-48f6-8478-0bd5887c8da0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A normal retriever (like a vector store retriever) does not inherently support conversational retrieval because\\n it only fetches documents based on the current query—it does not consider past interactions.\\n This function - create_retrieval_chain supports conversational retrieval on top of the standard retrieval.\\n It takes a retriever and chain made out of a prompt template.\\n'"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "# RAG pipeline setup:\n",
        "# - `qa_prompt`: Defines how the assistant answers using retrieved context and chat history.\n",
        "# - `question_answer_chain`: Combines retrieved documents to generate responses.\n",
        "# - `rag_chain`: Links retrieval with the response generator, ensuring context-aware answers.\n",
        "qa_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant. Use the following context to answer the user's question.\"),\n",
        "    (\"system\", \"Context: {context}\"),\n",
        "    MessagesPlaceholder(\"chat_history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# `create_stuff_documents_chain`: Merges retrieved documents into a structured prompt.\n",
        "# Ensures all relevant content is formatted before passing it to the LLM for response generation.\n",
        "# This step improves contextual understanding by consolidating multiple sources into a single coherent input.\n",
        "question_answer_chain = create_stuff_documents_chain(google_llm, qa_prompt)\n",
        "\n",
        "# `create_retrieval_chain`: Retrieves relevant documents based on the query\n",
        "# and passes them to the response generation chain for context-aware answers.\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"A normal retriever (like a vector store retriever) does not inherently support conversational retrieval because\n",
        " it only fetches documents based on the current query—it does not consider past interactions.\n",
        " This function - create_retrieval_chain supports conversational retrieval on top of the standard retrieval.\n",
        " It takes a retriever and chain made out of a prompt template.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPjXrLGOV_66",
        "outputId": "39da0ee4-6169-4210-efe8-e1da6859f2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'answer': \"The provided text doesn't specify the headquarters location of \"\n",
            "           'GreenGrow Innovations.  It only mentions that they have offices in '\n",
            "           'California and Iowa.',\n",
            " 'chat_history': [HumanMessage(content='When was GreenGrow innovations founded?', additional_kwargs={}, response_metadata={}),\n",
            "                  AIMessage(content='The provided text does not state when GreenGrow Innovations was founded.  It only mentions that their breakthrough was in 2018.', additional_kwargs={}, response_metadata={})],\n",
            " 'context': [Document(metadata={'start_index': 979, 'source': '/content/GreenGrow Innovations_ Company History.docx'}, page_content=\"The company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\n\\n\\n\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\n\\n\\n\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\"),\n",
            "             Document(metadata={'start_index': 979, 'source': '/content/GreenGrow Innovations_ Company History.docx'}, page_content=\"The company's breakthrough came in 2018 with the introduction of the EcoHarvest System, an integrated solution that combined smart irrigation, soil monitoring, and automated harvesting techniques. This system caught the attention of large-scale farmers across the United States, propelling GreenGrow to national prominence.\\n\\n\\n\\nToday, GreenGrow Innovations employs over 200 people and has expanded its operations to include offices in California and Iowa. The company continues to focus on developing sustainable agricultural technologies, with ongoing projects in vertical farming, drought-resistant crop development, and AI-powered farm management systems.\\n\\n\\n\\nDespite its growth, GreenGrow remains committed to its original mission of promoting sustainable farming practices. The company regularly partners with universities and research institutions to advance the field of agricultural technology and hosts annual conferences to share knowledge with farmers and other industry professionals.\"),\n",
            "             Document(metadata={'source': '/content/Company_ GreenFields BioTech.docx', 'start_index': 0}, page_content='Company: GreenFields BioTech\\n\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.'),\n",
            "             Document(metadata={'start_index': 0, 'source': '/content/Company_ GreenFields BioTech.docx'}, page_content='Company: GreenFields BioTech\\n\\nHeadquarters: GreenFields BioTech is headquartered in Zurich, Switzerland. Known for its groundbreaking research in sustainable agriculture and biotechnology, the company has strategically positioned itself in Zurich, a city recognized for its leadership in scientific research and innovation. This location provides GreenFields BioTech with an ideal environment to collaborate with leading academic institutions and industry experts, driving forward its mission to create eco-friendly farming solutions.')],\n",
            " 'input': 'Where it is headquarted?'}\n"
          ]
        }
      ],
      "source": [
        "# Invoking the created retrieval chain\n",
        "result = rag_chain.invoke({\"input\": \"Where it is headquarted?\", \"chat_history\": chat_history})\n",
        "\n",
        "pprint(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENfElAVLXbAD"
      },
      "source": [
        "Building a Multi User Chatbot\n",
        "\n",
        "Using Sqlite3 database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "wJmV81tDWNgg"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "DB_NAME = \"rag_app.db\"\n",
        "\n",
        "def get_db_connection():\n",
        "  conn = sqlite3.connect(DB_NAME)\n",
        "  conn.row_factory = sqlite3.Row\n",
        "  return conn\n",
        "\n",
        "def create_application_logs():\n",
        "  conn = get_db_connection()\n",
        "  cursor = conn.execute('''CREATE TABLE IF NOT EXISTS application_logs\n",
        "                        (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                        session_id TEXT,\n",
        "                        user_query TEXT,\n",
        "                        llm_response TEXT,\n",
        "                        model TEXT,\n",
        "                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)\n",
        "                        ''')\n",
        "  conn.close()\n",
        "\n",
        "def insert_application_logs(session_id, user_query, llm_response, model):\n",
        "  conn = get_db_connection()\n",
        "  conn.execute('INSERT INTO application_logs (session_id, user_query, llm_response, model) VALUES (?, ?, ?, ?)',\n",
        "               (session_id, user_query, llm_response, model))\n",
        "  conn.commit()\n",
        "  conn.close()\n",
        "\n",
        "def get_chat_history(session_id):\n",
        "  conn = get_db_connection()\n",
        "  cursor = conn.execute('SELECT * FROM application_logs WHERE session_id = ? ORDER BY created_at', (session_id,))\n",
        "  messages = []\n",
        "  for row in cursor.fetchall():\n",
        "    messages.extend([\n",
        "        {\"role\":\"human\", \"content\": row['user_query']},\n",
        "        {\"role\":\"ai\", \"content\": row['llm_response']}\n",
        "    ])\n",
        "  conn.close()\n",
        "  return messages\n",
        "\n",
        "# Initialize the database\n",
        "create_application_logs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9wsrbHLX1Ee",
        "outputId": "31238bd1-eabf-4cf7-9fd2-c0475e00beae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "{'content': \"That depends on which company you're asking about.  To answer \"\n",
            "            'your question, please specify the company name (TechWave '\n",
            "            'Innovations or GreenFields BioTech).',\n",
            " 'role': 'ai'}\n"
          ]
        }
      ],
      "source": [
        "# USER 1\n",
        "\n",
        "import uuid\n",
        "session_id = str(uuid.uuid4())\n",
        "\n",
        "chat_history = get_chat_history(session_id)\n",
        "print(chat_history)\n",
        "\n",
        "question1 = \"Where is this company available?\"\n",
        "answer1 = rag_chain.invoke({\"input\": question1, \"chat_history\": chat_history})['answer']\n",
        "insert_application_logs(session_id, question1, answer1, google_llm.model)\n",
        "\n",
        "chat_history.extend([\n",
        "    {\"role\":\"human\", \"content\": question1},\n",
        "    {\"role\":\"ai\", \"content\": answer1}\n",
        "])\n",
        "pprint(chat_history[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLiN6eRLX34W",
        "outputId": "50be5e70-7641-4fc6-c72b-dc73398480e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Please specify which company you are asking about.  I need to know whether '\n",
            " 'you want to know about TechWave Innovations or GreenFields BioTech.')\n"
          ]
        }
      ],
      "source": [
        "question2 = \"What does it do?\"\n",
        "# Using same session id considers chat history while answering a new question\n",
        "chat_history = get_chat_history(session_id)\n",
        "answer2 = rag_chain.invoke({\"input\": question2, \"chat_history\": chat_history})['answer']\n",
        "insert_application_logs(session_id, question2, answer2, google_llm.model)\n",
        "\n",
        "pprint(answer2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUr32BwfX7WJ",
        "outputId": "bcf11cf1-e8a2-4875-d22b-6b71fa5ccfba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': 'Where is this company available?', 'role': 'human'},\n",
            " {'content': \"That depends on which company you're asking about.  To answer \"\n",
            "             'your question, please specify the company name (TechWave '\n",
            "             'Innovations or GreenFields BioTech).',\n",
            "  'role': 'ai'},\n",
            " {'content': 'What does it do?', 'role': 'human'},\n",
            " {'content': \"Please specify which company you're asking about (TechWave \"\n",
            "             'Innovations or GreenFields BioTech).  I need to know which '\n",
            "             \"company you're referring to in order to describe what it does.\",\n",
            "  'role': 'ai'},\n",
            " {'content': 'What does it do?', 'role': 'human'},\n",
            " {'content': 'Please specify which company you are asking about.  I need to '\n",
            "             'know whether you want to know about TechWave Innovations or '\n",
            "             'GreenFields BioTech.',\n",
            "  'role': 'ai'}]\n"
          ]
        }
      ],
      "source": [
        "chat_history = get_chat_history(session_id)\n",
        "pprint(chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLLwhUDtX_YY",
        "outputId": "9f769138-9329-465e-bb53-5dd4737839df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'human', 'content': 'Where is this company available?'}, {'role': 'ai', 'content': \"That depends on which company you're asking about.  To answer your question, please specify the company name (TechWave Innovations or GreenFields BioTech).\"}, {'role': 'human', 'content': 'What does it do?'}, {'role': 'ai', 'content': \"Please specify which company you're asking about (TechWave Innovations or GreenFields BioTech).  I need to know which company you're referring to in order to describe what it does.\"}, {'role': 'human', 'content': 'What does it do?'}, {'role': 'ai', 'content': 'Please specify which company you are asking about.  I need to know whether you want to know about TechWave Innovations or GreenFields BioTech.'}]\n",
            "{'content': 'GreenFields BioTech is a company headquartered in Zurich, '\n",
            "            'Switzerland.  It conducts groundbreaking research in sustainable '\n",
            "            'agriculture and biotechnology, focusing on creating eco-friendly '\n",
            "            'farming solutions.  They are known for their EcoHarvest System, '\n",
            "            'which is continually being refined and expanded.  Recent updates '\n",
            "            'include integration with weather forecasting services for better '\n",
            "            'long-term planning and a module for managing crop rotation to '\n",
            "            'improve soil health and biodiversity.',\n",
            " 'role': 'ai'}\n"
          ]
        }
      ],
      "source": [
        "chat_history = get_chat_history(session_id)\n",
        "print(chat_history)\n",
        "\n",
        "question1 = \"It is GreenFields BioTech\"\n",
        "answer1 = rag_chain.invoke({\"input\": question1, \"chat_history\": chat_history})['answer']\n",
        "insert_application_logs(session_id, question1, answer1, google_llm.model)\n",
        "\n",
        "chat_history.extend([\n",
        "    {\"role\":\"human\", \"content\": question1},\n",
        "    {\"role\":\"ai\", \"content\": answer1}\n",
        "])\n",
        "pprint(chat_history[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy--qyroYLhb",
        "outputId": "04bacc31-70cd-4b7d-a1f4-013a397a3d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[{'content': 'When was JPMC founded?', 'role': 'human'},\n",
            " {'content': 'This question cannot be answered from the given context.  The '\n",
            "             'provided text is about TechWave Innovations and its EcoHarvest '\n",
            "             'system; it contains no information about JPMorgan Chase (JPMC).',\n",
            "  'role': 'ai'}]\n"
          ]
        }
      ],
      "source": [
        "# Generating a new session key for new user\n",
        "session_id = str(uuid.uuid4())\n",
        "\n",
        "chat_history = get_chat_history(session_id)\n",
        "print(chat_history)\n",
        "\n",
        "question = \"When was JPMC founded?\"\n",
        "answer = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})['answer']\n",
        "insert_application_logs(session_id, question, answer, google_llm.model)\n",
        "\n",
        "chat_history.extend([\n",
        "    {\"role\":\"human\", \"content\": question},\n",
        "    {\"role\": \"ai\", \"content\": answer}\n",
        "])\n",
        "\n",
        "pprint(chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm8KJF4cYSS-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
